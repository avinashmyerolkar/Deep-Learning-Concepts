{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VKi4ezZDqikY"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "from keras import Sequential\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test)= mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtgVQ3sCrdwd",
        "outputId": "bcd4524e-a15b-4e02-8fa9-f8e2caaf98a9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# When padding = valid / when we will not apply padding before convolution we may loose information as image size reduces , and also central features of images get more weightage \n",
        "# compared to edge features during convolutional operation for ex. "
      ],
      "metadata": {
        "id": "ACaKJCKNryTm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "knq3ZE563KTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.engine import input_spec\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding=\"valid\",activation='relu',input_shape=(28,28,1))) # total 32 filters of 3*3 size is used , without padding\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding=\"valid\",activation='relu',input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding=\"valid\",activation='relu',input_shape=(28,28,1))) # total 3 convolutional layers will be there\n",
        "model.add(Flatten())   # will flatten 2dimensional array to 1Dimensional array to give input to fully connected layes for classification using softmax activation function\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))   # As for we have to do classification of 10 digits (0 to 9) \n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nez0FIvQsbih",
        "outputId": "33700120-f459-43c7-8781-79b9fbfbd3e1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 22, 22, 32)        9248      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 15488)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1982592   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,002,698\n",
            "Trainable params: 2,002,698\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of Parameters = (Kernel Width * Kernel Height * Input Channels + 1) * Output Channels\n",
        "#In this case:\n",
        "# Kernel Width: 3\n",
        "# Kernel Height: 3\n",
        "# Input Channels: 1 (grayscale image)\n",
        "# Output Channels: 32\n",
        "# Substituting these values into the formula:\n",
        "# Number of Parameters = (3 * 3 * 1 + 1) * 32 = 320\n",
        "\n",
        "\n",
        "# Second Conv2D layer:\n",
        "# Number of filters: 32\n",
        "# Kernel size: (3, 3)\n",
        "# Padding: \"valid\"\n",
        "# Activation function: ReLU\n",
        "# Input shape: (28, 28, 1)\n",
        "# Again, using the formula:\n",
        "# Number of Parameters = (3 * 3 * 32 + 1) * 32 = 9248\n",
        "\n",
        "# Third Conv2D layer:\n",
        "# Number of filters: 32\n",
        "# Kernel size: (3, 3)\n",
        "# Padding: \"valid\"\n",
        "# Activation function: ReLU\n",
        "# Input shape: (28, 28, 1)\n",
        "# Applying the formula once more:\n",
        "# Number of Parameters = (3 * 3 * 32 + 1) * 32 = 9248\n",
        "# The third Conv2D layer also has 9,248 parameters.\n",
        "\n",
        "\n",
        "# Flatten layer:\n",
        "# No learnable parameters. It reshapes the output of the previous layer i.e, 3rd conv2D layes to a 1D vector.\n",
        "# input for flatten layer is (22*22*32) = 15488 parametres\n",
        "\n",
        "\n",
        "# First Dense layer:\n",
        "# Number of neurons: 128\n",
        "# Activation function: ReLU\n",
        "# Since this is a Dense layer, the input shape is determined by the output shape of the previous layer.\n",
        "# In this case, it is a flattened vector of size (None, 15,488) because the output of the previous Flatten layer is (None, 15,488).\n",
        "# Using the formula:\n",
        "# Number of Parameters = (15,488+1) * 128 = 19,82,592 parametres\n",
        "\n",
        "\n",
        "# Second Dense layer:\n",
        "# Number of neurons: 10\n",
        "# Activation function: Softmax\n",
        "# Using the formula:\n",
        "# Number of Parameters = (128 + 1) * 10 = 1,290\n",
        "# Therefore, the total number of parameters in the model can be obtained by summing the parameters from all the layers:\n",
        "\n",
        "\n",
        "# Total Parameters = 320 + 9,248 + 9,248 + 19,82,592 + 1,290 = 20,02,698\n",
        "# The model summary will display the same information, including the number of trainable parameters for each layer."
      ],
      "metadata": {
        "id": "I2HbgRGJxA2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# When padding = same / when we will apply padding before convolution we will not loose information as image size will not reduce.\n",
        "# and hence central edge features in a way will get same importance , as indirectly we are bringing edge features at the centre by adding padding near edges of image"
      ],
      "metadata": {
        "id": "vbOr1uZp3Lky"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='same',activation='relu'))\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='same',activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9JBzlzX3rFl",
        "outputId": "f5c1c426-470e-4fc9-ecf3-7929e01abeb2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_7 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               3211392   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,231,498\n",
            "Trainable params: 3,231,498\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see output shape of image after every convolutional operation is same as input layer and hence no information loss would happen if we do convolution by applying padding"
      ],
      "metadata": {
        "id": "U3zqD8J-82oD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xsRLo-EJ9Mes"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PlqeUN-t9IPV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}